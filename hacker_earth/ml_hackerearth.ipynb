{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r machine_hack/kmodel_dir/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, metrics, utils\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "# plt.figure(figsize=(1, 6))\n",
    "# sns.countplot(train_df['breed'])\n",
    "# # ax = sns.barplot(x=\"breed\", y=\"Frequency\", data=train_df['breed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classes = [train_df['breed'].value_counts().index[i] for i in range(0, len(train_df['breed'].value_counts())) \n",
    "               if train_df['breed'].value_counts().values[i] < 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "for x in new_classes:\n",
    "    datap = train_df[train_df['breed'] == x]\n",
    "    final_df = final_df.append(datap)\n",
    "\n",
    "final_df.index = list(range(0, len(final_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = model_selection.train_test_split(final_df, test_size=.1, stratify=final_df['breed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r data/train\n",
    "!rm -r data/valid\n",
    "!mkdir data/train\n",
    "!mkdir data/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in final_df['breed'].value_counts().index:\n",
    "    subprocess.call(['mkdir', 'data/train/' + x])\n",
    "    subprocess.call(['mkdir', 'data/valid/' + x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(train)):\n",
    "    name = train['image_id'].iloc[i]\n",
    "    label = train['breed'].iloc[i]\n",
    "    shutil.copy('dataset/train/'+name+'.jpg', 'data/train/'+label+'/'+name+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(valid)):\n",
    "    name = valid['image_id'].iloc[i]\n",
    "    label = valid['breed'].iloc[i]\n",
    "    shutil.copy('dataset/train/'+name+'.jpg', 'data/valid/'+label+'/'+name+'.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification for classification fouls or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are retrieved using bing image downloader api and the model is created using tensorflow and tensorflow hub"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from bing_image_downloader import downloader\n",
    "query_string = 'sliding fouls football'\n",
    "downloader.download(query_string, limit=300,  output_dir='dataset', adult_filter_off=True, force_replace=False, timeout=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model_dir/modelfinal.h5', save_best_only=True,\n",
    "                                      monitor='val_accuracy'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='model_dir/logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using https://tfhub.dev/google/imagenet/mobilenet_v2_035_192/feature_vector/4 with input size (192, 192)\n"
     ]
    }
   ],
   "source": [
    "module_selection = (\"mobilenet_v2_035_192\", 192)\n",
    "handle_base, pixels = module_selection\n",
    "MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/{}/feature_vector/4\".format(handle_base)\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n",
    "BATCH_SIZE = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 311 images belonging to 28 classes.\n",
      "Found 2793 images belonging to 28 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen_kwargs = dict(rescale=1./255)\n",
    "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, interpolation=\"bilinear\")\n",
    "\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
    "valid_generator = valid_datagen.flow_from_directory('data/valid/', \n",
    "                                                    shuffle=True,  \n",
    "                                                    **dataflow_kwargs)\n",
    "\n",
    "do_data_augmentation = False \n",
    "if do_data_augmentation:\n",
    "      train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "          rotation_range=40,\n",
    "          horizontal_flip=True,\n",
    "          width_shift_range=0.2, height_shift_range=0.2,\n",
    "          shear_range=0.2, zoom_range=0.2,\n",
    "          **datagen_kwargs)\n",
    "else:\n",
    "      train_datagen = valid_datagen\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('data/train/', \n",
    "                                                    shuffle=True, \n",
    "                                                    **dataflow_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with https://tfhub.dev/google/imagenet/mobilenet_v2_035_192/feature_vector/4\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_3 (KerasLayer)   (None, 1280)              410208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1280)              5120      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 28)                35868     \n",
      "=================================================================\n",
      "Total params: 451,196\n",
      "Trainable params: 38,428\n",
      "Non-trainable params: 412,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "do_fine_tuning = False\n",
    "\n",
    "print(\"Building model with\", MODULE_HANDLE)\n",
    "model = tf.keras.Sequential([\n",
    "    # Explicitly define the input shape so the model can be properly\n",
    "    # loaded by the TFLiteConverter\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)), hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(rate=0.1),\n",
    "    tf.keras.layers.Dense(train_generator.num_classes,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.00001))\n",
    "])\n",
    "model.build((None,)+IMAGE_SIZE+(3,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = utils.class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.01),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "87/87 [==============================] - 19s 220ms/step - loss: 4.0489 - accuracy: 0.1699 - val_loss: 2.7469 - val_accuracy: 0.2604\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 18s 211ms/step - loss: 2.4949 - accuracy: 0.3466 - val_loss: 3.0977 - val_accuracy: 0.2465\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 19s 213ms/step - loss: 1.9780 - accuracy: 0.4603 - val_loss: 3.4467 - val_accuracy: 0.2083\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 18s 212ms/step - loss: 1.6443 - accuracy: 0.5212 - val_loss: 3.6700 - val_accuracy: 0.2153\n",
      "Epoch 5/100\n",
      "68/87 [======================>.......] - ETA: 3s - loss: 1.3752 - accuracy: 0.5889"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
    "hist = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100, steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    class_weight=class_weights,\n",
    "    shuffle=True,\n",
    "    validation_steps=validation_steps).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,5])\n",
    "plt.plot(hist[\"loss\"])\n",
    "plt.plot(hist[\"val_loss\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(hist[\"accuracy\"])\n",
    "plt.plot(hist[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model = tf.keras.models.Sequential()\n",
    "c_model.add(tf.keras.layers.Conv2D(32, (3, 3), input_shape=(IMAGE_SHAPE[0], IMAGE_SHAPE[1], 3)))\n",
    "c_model.add(tf.keras.layers.Activation('relu'))\n",
    "c_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "c_model.add(tf.keras.layers.Conv2D(64, (3, 3)))\n",
    "c_model.add(tf.keras.layers.Activation('relu'))\n",
    "c_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "c_model.add(tf.keras.layers.Conv2D(128, (3, 3)))\n",
    "c_model.add(tf.keras.layers.Activation('relu'))\n",
    "c_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "c_model.add(tf.keras.layers.Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "c_model.add(tf.keras.layers.Dense(64))\n",
    "c_model.add(tf.keras.layers.Activation('relu'))\n",
    "c_model.add(tf.keras.layers.Dropout(0.5))\n",
    "c_model.add(tf.keras.layers.Dense(train_generator.num_classes))\n",
    "c_model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "\n",
    "c_model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.01),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
    "c_hist = c_model.fit(\n",
    "    train_generator,\n",
    "    epochs=50, steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    class_weight=class_weights,\n",
    "    validation_steps=validation_steps).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# training for 10 epochs\n",
    "epochs = 30\n",
    "# size of each image\n",
    "IMAGE_SHAPE = (224, 224, 3)\n",
    "\n",
    "\n",
    "valid_data_gen = ImageDataGenerator(rescale=1/255)\n",
    "train_data_gen = ImageDataGenerator(\n",
    "                                    rescale=1./255,\n",
    "                                    rotation_range=30,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.4,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    channel_shift_range=0.4\n",
    "                                   )\n",
    "# make the training dataset generator\n",
    "train_image_generator = train_data_gen.flow_from_directory(directory='data/train/', batch_size=batch_size,\n",
    "                                                     target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]),\n",
    "                                                        shuffle=True)\n",
    "# make the validation dataset generator\n",
    "valid_image_generator = valid_data_gen.flow_from_directory(directory='data/valid/', batch_size=batch_size, \n",
    "                                                     target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]),\n",
    "                                                     shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_class_weights = utils.class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_image_generator.classes), train_image_generator.classes)\n",
    "k_class_weights = dict(enumerate(k_class_weights))\n",
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "conv_base = tf.keras.applications.MobileNetV2(input_shape=input_shape, weights='imagenet')\n",
    "\n",
    "k_model = tf.keras.models.Sequential()\n",
    "k_model.add(conv_base)\n",
    "k_model.add(tf.keras.layers.BatchNormalization())\n",
    "k_model.add(tf.keras.layers.Dropout(0.2))\n",
    "k_model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "k_model.add(tf.keras.layers.Dropout(0.5))\n",
    "k_model.add(tf.keras.layers.Dense(train_image_generator.num_classes))\n",
    "\n",
    "for layer in k_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# print the summary of the model architecture\n",
    "# k_model.summary()\n",
    "k_model.compile(\n",
    "                optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "                metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.TopKCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='kmodel_dir/modelfinal.h5', save_best_only=True,\n",
    "                                      monitor='val_accuracy'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='kmodel_dir/logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps_per_epoch = np.ceil(train_image_generator.samples / batch_size)\n",
    "validation_steps_per_epoch = np.ceil(valid_image_generator.samples / batch_size)\n",
    "# train using the generators\n",
    "k_hist = k_model.fit(train_image_generator, \n",
    "              steps_per_epoch=training_steps_per_epoch,\n",
    "              validation_data=valid_image_generator, \n",
    "              validation_steps=validation_steps_per_epoch,\n",
    "              epochs=epochs,\n",
    "              class_weight=k_class_weights,\n",
    "              verbose=1, \n",
    "              callbacks=k_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictions:\n",
    "    \n",
    "    def __init__(self, image_dir, model, test_df, x, y):\n",
    "        self.image_dir = image_dir\n",
    "        self.model = model\n",
    "        self.test_df = test_df\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, image_name):\n",
    "        self.image_name = image_name\n",
    "        test_img = cv2.imread(os.path.join(self.image_dir, self.image_name))\n",
    "        test_img = np.resize(test_img, (1, self.x, self.y, 3))\n",
    "        tf_model_predictions = self.model.predict(test_img)\n",
    "        id_ = np.argmax(tf_model_predictions[0])\n",
    "        \n",
    "        return tf_model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_generator.class_indices\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "image_ids = list(test_df['image_id'])\n",
    "\n",
    "test_results = []\n",
    "for x in image_ids:\n",
    "    set_f = {}\n",
    "    x_name = x + '.jpg'\n",
    "    prediction_module = Predictions('dataset/test/', model, 'test', 160, 160)\n",
    "    predits = Predictions.predict(prediction_module, x_name)\n",
    "    pred_label = np.argmax(predits[0])\n",
    "    set_f['image_id'] = x\n",
    "    set_f['breed'] = pred_label\n",
    "    test_results.append(set_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame(test_results)\n",
    "test_results_df['breed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id = {}\n",
    "for id,val in enumerate(train_generator.class_indices): \n",
    "    new_id[id] = val \n",
    "    \n",
    "test_results_df['breed'] = [new_id[x] for x in test_results_df['breed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_results_df.drop(['id-preds'], axis=1, inplace=True)\n",
    "test_results_df.to_csv('results/vishnu_submit.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, x, y, batch_size, train_path, valid_path):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.train_path = train_path\n",
    "        self.valid_path = valid_path\n",
    "    \n",
    "    def generator(self):\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                                            rescale=1./255,\n",
    "                                            rotation_range=30,\n",
    "                                            width_shift_range=0.2,\n",
    "                                            height_shift_range=0.4,\n",
    "                                            shear_range=0.2,\n",
    "                                            zoom_range=0.2,\n",
    "                                            channel_shift_range=0.4,\n",
    "                                            fill_mode=\"nearest\",\n",
    "                                            cval=0.4,\n",
    "                                            horizontal_flip=True,\n",
    "                                            vertical_flip=True\n",
    "                                           )\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "                                                            self.train_path,  # this is the target directory\n",
    "                                                            target_size=(self.x, self.y),  # all images will be resized to 150x150\n",
    "                                                            batch_size=self.batch_size,\n",
    "                                                            class_mode='categorical')\n",
    "\n",
    "        valid_generator = test_datagen.flow_from_directory(\n",
    "                                                            self.valid_path,\n",
    "                                                            target_size=(self.x, self.y),\n",
    "                                                            batch_size=self.batch_size,\n",
    "                                                            class_mode='categorical')\n",
    "        \n",
    "        return train_generator, valid_generator\n",
    "    \n",
    "class Model:\n",
    "    def __init__(self, train_generator, valid_generator, met, los, model_link, x, y, class_weight, callbacks):\n",
    "        self.train_generator = train_generator\n",
    "        self.valid_generator = valid_generator\n",
    "        self.met = met\n",
    "        self.los = los\n",
    "        self.model_link = model_link\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.class_weight = class_weight\n",
    "        self.callbacks = callbacks\n",
    "    \n",
    "    def compiler(self, dropout):\n",
    "        self.dropout = dropout\n",
    "        tl_model = tf.keras.Sequential([\n",
    "                    hub.KerasLayer(self.model_link, trainable=True),\n",
    "                    tf.keras.layers.Dropout(self.dropout),\n",
    "                    tf.keras.layers.Dense(self.train_generator.num_classes,\n",
    "                                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "        ])\n",
    "        tl_model.build([None, self.x, self.y, 3])\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "        tl_model.compile(optimizer=optimizer, loss=self.los, metrics=self.met)\n",
    "        \n",
    "        return tl_model\n",
    "    \n",
    "    def train(self, epochs, model):\n",
    "        self.epochs = epochs\n",
    "        self.model = model\n",
    "        steps_per_epoch = np.ceil(self.train_generator.samples/self.train_generator.batch_size)\n",
    "        val_steps_per_epoch = np.ceil(self.valid_generator.samples/self.valid_generator.batch_size)\n",
    "        hist = self.model.fit(\n",
    "                            self.train_generator, \n",
    "                            epochs=self.epochs,\n",
    "                            verbose=1,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            class_weight=self.class_weight,\n",
    "                            callbacks=self.callbacks,\n",
    "                            validation_data=self.valid_generator,\n",
    "                            validation_steps=val_steps_per_epoch).history\n",
    "\n",
    "        return self.model, hist\n",
    "    \n",
    "met = tf.keras.metrics.Accuracy()\n",
    "los = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)\n",
    "model_weights = 'https://tfhub.dev/google/imagenet/mobilenet_v2_035_224/classification/4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocessing(224, 224, 8, 'data/train', 'data/valid')\n",
    "train_generator, valid_generator = Preprocessing.generator(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_class_model = Model(train_generator, \n",
    "                          valid_generator, \n",
    "                          met, los, \n",
    "                          model_weights, \n",
    "                          224, 224, \n",
    "                          class_weights,\n",
    "                          callbacks)\n",
    "tl_model = Model.compiler(image_class_model, 0.4)\n",
    "img_model, img_hist = Model.train(image_class_model, 40, tl_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictions:\n",
    "    \n",
    "    def __init__(self, image_dir, model, test_df, x, y):\n",
    "        self.image_dir = image_dir\n",
    "        self.model = model\n",
    "        self.test_df = test_df\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, image_name):\n",
    "        self.image_name = image_name\n",
    "        test_img = cv2.imread(os.path.join(self.image_dir, self.image_name))\n",
    "        test_img = np.resize(test_img, (1, self.x, self.y, 3))\n",
    "        tf_model_predictions = self.model.predict(test_img)\n",
    "        id_ = np.argmax(tf_model_predictions[0])\n",
    "        \n",
    "        return tf_model_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread('dataset/test/2006370aad.jpg', cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_generator.class_indices\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "image_ids = list(test_df['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "for x in image_ids:\n",
    "    set_f = {}\n",
    "    x_name = x + '.jpg'\n",
    "    prediction_module = Predictions('dataset/test/', img_model, 'test', 224, 224)\n",
    "    predits = Predictions.predict(prediction_module, x_name)\n",
    "    pred_label = np.argmax(predits[0])\n",
    "    set_f['id-preds'] = predits\n",
    "    set_f['image_id'] = x\n",
    "    set_f['breed'] = pred_label\n",
    "    test_results.append(set_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame(test_results)\n",
    "test_results_df['breed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df['id-preds'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df['breed'] = [new_id[x] for x in test_results_df['breed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df.to_csv('vishnu_submit.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r results.zip results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r results/.ipynb_checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id = {}\n",
    "for id,val in enumerate(train_generator.class_indices): \n",
    "    new_id[id] = val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
