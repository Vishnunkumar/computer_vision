{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir train/\n",
    "!mkdir valid/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir train/not_emergency/\n",
    "!mkdir train/emergency/\n",
    "\n",
    "!mkdir valid/not_emergency/\n",
    "!mkdir valid/emergency/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df, te_df = model_selection.train_test_split(df, test_size=.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_im = tr_df['image_names']\n",
    "te_im = te_df['image_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(tr_df)):\n",
    "    img_path = os.path.join('images/', tr_df['image_names'].iloc[i])\n",
    "    if tr_df['emergency_or_not'].iloc[i] == 0:\n",
    "        shutil.copy(img_path, 'train/not_emergency/')\n",
    "    else:\n",
    "        shutil.copy(img_path, 'train/emergency/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(te_df)):\n",
    "    img_path = os.path.join('images/', te_df['image_names'].iloc[i])\n",
    "    if te_df['emergency_or_not'].iloc[i] == 0:\n",
    "        shutil.copy(img_path, 'valid/not_emergency/')\n",
    "    else:\n",
    "        shutil.copy(img_path, 'valid/emergency/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency = \"1\"\n",
    "not_emergency = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, x, y, batch_size, train_path, valid_path):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.train_path = train_path\n",
    "        self.valid_path = valid_path\n",
    "    \n",
    "    def generator(self):\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                                            rescale=1./255,\n",
    "                                            rotation_range=30,\n",
    "                                            width_shift_range=0.2,\n",
    "                                            height_shift_range=0.4,\n",
    "                                            brightness_range=None,\n",
    "                                            shear_range=0.2,\n",
    "                                            zoom_range=0.2,\n",
    "                                            channel_shift_range=0.4,\n",
    "                                            fill_mode=\"nearest\",\n",
    "                                            cval=0.4,\n",
    "                                            horizontal_flip=True,\n",
    "                                            vertical_flip=True\n",
    "                                           )\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "                                                            self.train_path,  # this is the target directory\n",
    "                                                            target_size=(self.x, self.y),  # all images will be resized to 150x150\n",
    "                                                            batch_size=self.batch_size,\n",
    "                                                            class_mode='categorical')\n",
    "\n",
    "        valid_generator = test_datagen.flow_from_directory(\n",
    "                                                            self.valid_path,\n",
    "                                                            target_size=(self.x, self.y),\n",
    "                                                            batch_size=self.batch_size,\n",
    "                                                            class_mode='categorical')\n",
    "        \n",
    "        return train_generator, valid_generator\n",
    "    \n",
    "class Model:\n",
    "    def __init__(self, train_generator, valid_generator, met, los, model_link, x, y):\n",
    "        self.train_generator = train_generator\n",
    "        self.valid_generator = valid_generator\n",
    "        self.met = met\n",
    "        self.los = los\n",
    "        self.model_link = model_link\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def compiler(self, activation, dense1, dropout):\n",
    "        self.dense = dense1\n",
    "        self.dropout = dropout\n",
    "        self.activation = activation\n",
    "        tl_model = tf.keras.Sequential([\n",
    "                    hub.KerasLayer(self.model_link, trainable=False),\n",
    "                    tf.keras.layers.Dropout(self.dropout),\n",
    "                    tf.keras.layers.Dense(self.dense, activation='relu'),\n",
    "                    tf.keras.layers.Dense(self.train_generator.num_classes, activation=self.activation)\n",
    "                ])\n",
    "        tl_model.build([None, self.x, self.y, 3])\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "        tl_model.compile(optimizer=optimizer, loss=self.los, metrics=self.met)\n",
    "        \n",
    "        return tl_model\n",
    "    \n",
    "    def train(self, epochs, model):\n",
    "        self.epochs = epochs\n",
    "        self.model = model\n",
    "        steps_per_epoch = np.ceil(self.train_generator.samples/self.train_generator.batch_size)\n",
    "        val_steps_per_epoch = np.ceil(self.valid_generator.samples/self.valid_generator.batch_size)\n",
    "        hist = self.model.fit(\n",
    "                            self.train_generator, \n",
    "                            epochs=self.epochs,\n",
    "                            verbose=1,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            validation_data=self.valid_generator,\n",
    "                            validation_steps=val_steps_per_epoch).history\n",
    "\n",
    "        return self.model, hist\n",
    "    \n",
    "met = tf.keras.metrics.Accuracy()\n",
    "los = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "model_weights = 'https://tfhub.dev/google/imagenet/mobilenet_v2_075_224/classification/4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1316 images belonging to 2 classes.\n",
      "Found 330 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "83/83 [==============================] - 21s 251ms/step - loss: 0.6299 - accuracy: 0.1296 - val_loss: 0.6023 - val_accuracy: 0.2030\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - 20s 245ms/step - loss: 0.6200 - accuracy: 0.1976 - val_loss: 0.6019 - val_accuracy: 0.2045\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.6239 - accuracy: 0.2219 - val_loss: 0.6053 - val_accuracy: 0.2136\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.6316 - accuracy: 0.2637 - val_loss: 0.6037 - val_accuracy: 0.2470\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.6176 - accuracy: 0.2561 - val_loss: 0.6045 - val_accuracy: 0.2545\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.6210 - accuracy: 0.2728 - val_loss: 0.6046 - val_accuracy: 0.2742\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - 21s 251ms/step - loss: 0.6210 - accuracy: 0.2838 - val_loss: 0.6022 - val_accuracy: 0.2561\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.6222 - accuracy: 0.3005 - val_loss: 0.6047 - val_accuracy: 0.2742\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.6194 - accuracy: 0.3207 - val_loss: 0.5576 - val_accuracy: 0.3909\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - 20s 243ms/step - loss: 0.5779 - accuracy: 0.5562 - val_loss: 0.5437 - val_accuracy: 0.5939\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5714 - accuracy: 0.6972 - val_loss: 0.5473 - val_accuracy: 0.6470\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5809 - accuracy: 0.6790 - val_loss: 0.5510 - val_accuracy: 0.6939\n",
      "Epoch 13/50\n",
      "83/83 [==============================] - 20s 247ms/step - loss: 0.5898 - accuracy: 0.7010 - val_loss: 0.5518 - val_accuracy: 0.7015\n",
      "Epoch 14/50\n",
      "83/83 [==============================] - 20s 243ms/step - loss: 0.5890 - accuracy: 0.7052 - val_loss: 0.5579 - val_accuracy: 0.7485\n",
      "Epoch 15/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5728 - accuracy: 0.7694 - val_loss: 0.5499 - val_accuracy: 0.7833\n",
      "Epoch 16/50\n",
      "83/83 [==============================] - 21s 253ms/step - loss: 0.5748 - accuracy: 0.7739 - val_loss: 0.5503 - val_accuracy: 0.7970\n",
      "Epoch 17/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5727 - accuracy: 0.7785 - val_loss: 0.5420 - val_accuracy: 0.8303\n",
      "Epoch 18/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5768 - accuracy: 0.7690 - val_loss: 0.5510 - val_accuracy: 0.8106\n",
      "Epoch 19/50\n",
      "83/83 [==============================] - 20s 245ms/step - loss: 0.5733 - accuracy: 0.7800 - val_loss: 0.5432 - val_accuracy: 0.8258\n",
      "Epoch 20/50\n",
      "83/83 [==============================] - 20s 245ms/step - loss: 0.5682 - accuracy: 0.7967 - val_loss: 0.5418 - val_accuracy: 0.8197\n",
      "Epoch 21/50\n",
      "83/83 [==============================] - 20s 242ms/step - loss: 0.5715 - accuracy: 0.7922 - val_loss: 0.5467 - val_accuracy: 0.8333\n",
      "Epoch 22/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5798 - accuracy: 0.7857 - val_loss: 0.5563 - val_accuracy: 0.8045\n",
      "Epoch 23/50\n",
      "83/83 [==============================] - 20s 245ms/step - loss: 0.5681 - accuracy: 0.8119 - val_loss: 0.5486 - val_accuracy: 0.8273\n",
      "Epoch 24/50\n",
      "83/83 [==============================] - 20s 243ms/step - loss: 0.5657 - accuracy: 0.8218 - val_loss: 0.5489 - val_accuracy: 0.8470\n",
      "Epoch 25/50\n",
      "83/83 [==============================] - 21s 250ms/step - loss: 0.5835 - accuracy: 0.7667 - val_loss: 0.5457 - val_accuracy: 0.8545\n",
      "Epoch 26/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5656 - accuracy: 0.8161 - val_loss: 0.5473 - val_accuracy: 0.8621\n",
      "Epoch 27/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5607 - accuracy: 0.8412 - val_loss: 0.5467 - val_accuracy: 0.8758\n",
      "Epoch 28/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5643 - accuracy: 0.8150 - val_loss: 0.5461 - val_accuracy: 0.8697\n",
      "Epoch 29/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5706 - accuracy: 0.8104 - val_loss: 0.5451 - val_accuracy: 0.8621\n",
      "Epoch 30/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5616 - accuracy: 0.8260 - val_loss: 0.5469 - val_accuracy: 0.8561\n",
      "Epoch 31/50\n",
      "83/83 [==============================] - 20s 243ms/step - loss: 0.5649 - accuracy: 0.8279 - val_loss: 0.5426 - val_accuracy: 0.8697\n",
      "Epoch 32/50\n",
      "83/83 [==============================] - 20s 243ms/step - loss: 0.5676 - accuracy: 0.8214 - val_loss: 0.5462 - val_accuracy: 0.8788\n",
      "Epoch 33/50\n",
      "83/83 [==============================] - 21s 251ms/step - loss: 0.5718 - accuracy: 0.8100 - val_loss: 0.5471 - val_accuracy: 0.8727\n",
      "Epoch 34/50\n",
      "83/83 [==============================] - 20s 245ms/step - loss: 0.5729 - accuracy: 0.8153 - val_loss: 0.5497 - val_accuracy: 0.8788\n",
      "Epoch 35/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5682 - accuracy: 0.8275 - val_loss: 0.5517 - val_accuracy: 0.8697\n",
      "Epoch 36/50\n",
      "83/83 [==============================] - 20s 243ms/step - loss: 0.5638 - accuracy: 0.8321 - val_loss: 0.5504 - val_accuracy: 0.8697\n",
      "Epoch 37/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5689 - accuracy: 0.8134 - val_loss: 0.5455 - val_accuracy: 0.8682\n",
      "Epoch 38/50\n",
      "83/83 [==============================] - 20s 243ms/step - loss: 0.5714 - accuracy: 0.8112 - val_loss: 0.5467 - val_accuracy: 0.8576\n",
      "Epoch 39/50\n",
      "83/83 [==============================] - 20s 245ms/step - loss: 0.5777 - accuracy: 0.7926 - val_loss: 0.5483 - val_accuracy: 0.8621\n",
      "Epoch 40/50\n",
      "83/83 [==============================] - 20s 245ms/step - loss: 0.5821 - accuracy: 0.7876 - val_loss: 0.5488 - val_accuracy: 0.8636\n",
      "Epoch 41/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5763 - accuracy: 0.7964 - val_loss: 0.5486 - val_accuracy: 0.8667\n",
      "Epoch 42/50\n",
      "83/83 [==============================] - 21s 251ms/step - loss: 0.5714 - accuracy: 0.8191 - val_loss: 0.5441 - val_accuracy: 0.8682\n",
      "Epoch 43/50\n",
      "83/83 [==============================] - 20s 243ms/step - loss: 0.5651 - accuracy: 0.8264 - val_loss: 0.5443 - val_accuracy: 0.8727\n",
      "Epoch 44/50\n",
      "83/83 [==============================] - 20s 245ms/step - loss: 0.5645 - accuracy: 0.8404 - val_loss: 0.5544 - val_accuracy: 0.8606\n",
      "Epoch 45/50\n",
      "83/83 [==============================] - 20s 245ms/step - loss: 0.5654 - accuracy: 0.8408 - val_loss: 0.5461 - val_accuracy: 0.8758\n",
      "Epoch 46/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5738 - accuracy: 0.8245 - val_loss: 0.5502 - val_accuracy: 0.8848\n",
      "Epoch 47/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5727 - accuracy: 0.8302 - val_loss: 0.5490 - val_accuracy: 0.8682\n",
      "Epoch 48/50\n",
      "83/83 [==============================] - 20s 246ms/step - loss: 0.5738 - accuracy: 0.8317 - val_loss: 0.5482 - val_accuracy: 0.8818\n",
      "Epoch 49/50\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.5667 - accuracy: 0.8431 - val_loss: 0.5561 - val_accuracy: 0.8682\n",
      "Epoch 50/50\n",
      "83/83 [==============================] - 20s 247ms/step - loss: 0.5722 - accuracy: 0.8347 - val_loss: 0.5510 - val_accuracy: 0.8773\n"
     ]
    }
   ],
   "source": [
    "preprocess = Preprocessing(224, 224, 16, 'train/', 'valid/')\n",
    "train_generator, valid_generator = Preprocessing.generator(preprocess)\n",
    "\n",
    "image_class_model = Model(train_generator, valid_generator, met, los, model_weights, 224, 224)\n",
    "tl_model = Model.compiler(image_class_model, 'sigmoid', 2560, 0.5)\n",
    "img_model, img_hist = Model.train(image_class_model, 50, tl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictions:\n",
    "    \n",
    "    def __init__(self, image_dir, model, test_df, x, y):\n",
    "        self.image_dir = image_dir\n",
    "        self.model = model\n",
    "        self.test_df = test_df\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, image_name):\n",
    "        self.image_name = image_name\n",
    "        test_img = cv2.imread(os.path.join(self.image_dir, self.image_name))\n",
    "        test_img = np.resize(test_img, (1, self.x, self.y, 3))\n",
    "        tf_model_predictions = self.model.predict(test_img)\n",
    "        id_ = np.argmax(tf_model_predictions)\n",
    "        \n",
    "        return image_name, id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795.jpg 0\n"
     ]
    }
   ],
   "source": [
    "prediction_module = Predictions('images/', img_model, test, 224, 224)\n",
    "name, label = Predictions.predict(prediction_module, test['image_names'].iloc[47])\n",
    "print(name, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
